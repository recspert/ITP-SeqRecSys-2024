{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "username = 'recspert'\n",
    "repo = 'ITP-SeqRecSys-2024'\n",
    "\n",
    "# remove local directory if it already exists\n",
    "if os.path.isdir(repo):\n",
    "    !rm -rf {repo}\n",
    "\n",
    "!git clone https://github.com/{username}/{repo}.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interactions_matrix(data, data_description, rebase_users=False):\n",
    "    '''\n",
    "    Converts a pandas dataframe with user-item interactions into a sparse matrix representation.\n",
    "    Allows reindexing user ids, which help ensure data consistency at the scoring stage\n",
    "    (assumes user ids are sorted in the scoring array).\n",
    "    \n",
    "    Args:\n",
    "        data (pandas.DataFrame): The input dataframe containing the user-item interactions.\n",
    "        data_description (dict): A dictionary containing the data description with the following keys:\n",
    "            - 'n_users' (int): The total number of unique users in the data.\n",
    "            - 'n_items' (int): The total number of unique items in the data.\n",
    "            - 'users' (str): The name of the column in the dataframe containing the user ids.\n",
    "            - 'items' (str): The name of the column in the dataframe containing the item ids.\n",
    "            - 'feedback' (str): The name of the column in the dataframe containing the user-item interaction feedback.\n",
    "        rebase_users (bool, optional): Whether to reindex the user ids to make contiguous index starting from 0. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: A sparse matrix of shape (n_users, n_items) containing the user-item interactions.\n",
    "    '''\n",
    "\n",
    "    data_sorted = data.sort_values(by=[data_description['timestamp']])\n",
    "    data_sorted['reciprocal_rank'] = 1.0 / (data_sorted.groupby(data_description['users']).cumcount(ascending=False) + 1)\n",
    "    \n",
    "    n_users = data_description['n_users']\n",
    "    n_items = data_description['n_items']\n",
    "    # get indices of observed data\n",
    "    user_idx = data_sorted[data_description['users']].values\n",
    "    if rebase_users: # handle non-contiguous index of test users\n",
    "        # This ensures that all user ids are contiguous and start from 0,\n",
    "        # which helps ensure data consistency at the scoring stage.\n",
    "        user_idx, user_index = pd.factorize(user_idx, sort=True)\n",
    "        n_users = len(user_index)\n",
    "    item_idx = data_sorted[data_description['items']].values\n",
    "    feedback = np.ones_like(item_idx)\n",
    "    # construct rating matrix\n",
    "    return csr_matrix((feedback, (user_idx, item_idx)), shape=(n_users, n_items), dtype='f8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good old MovieLens-1M\n",
    "\n",
    "data = get_movielens_data(include_time=True)\n",
    "\n",
    "data_description = {\n",
    "    'users':'userid',\n",
    "    'items':'movieid',\n",
    "    'feedback':'rating',\n",
    "    'timestamp':'timestamp'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./plots/split.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the timepoint corresponding to the 95% percentile\n",
    "test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.95, interpolation='nearest'\n",
    ")\n",
    "\n",
    "# interaction after timepoint go to test\n",
    "test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "# interaction before timepoint go to train,\n",
    "# also hiding the interactions of test users\n",
    "# this ensures the warm-start strategy\n",
    "train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform user and item ids for convenience, reindex test data\n",
    "training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "\n",
    "# reindex items in test set, if item was not in train, assign -1 as itemid\n",
    "test_data = reindex(test_data_, data_index['items'], filter_invalid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Successive evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./plots/eval.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the items that were not in the training set have itemid -1\n",
    "# let's drop the items with itemid -1 and all consequtive interactions\n",
    "test_data = test_data.sort_values(by=[data_description['users'], data_description['timestamp']])\n",
    "mask = test_data.groupby(data_description['users']).cummin()[data_description['items']] == -1\n",
    "test_data_truncated = test_data[~mask]\n",
    "\n",
    "# also get rid of users who have just 1 interaction\n",
    "interaction_counts = test_data_truncated.groupby(data_description['users']).size()\n",
    "users_to_keep = interaction_counts[interaction_counts >= 2].index\n",
    "test_prepared = test_data_truncated[test_data_truncated[data_description['users']].isin(users_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and test by users\n",
    "\n",
    "unique_users = test_prepared[data_description['users']].unique()\n",
    "np.random.shuffle(unique_users)\n",
    "\n",
    "# split the users into two halves\n",
    "split_index = len(unique_users) // 2\n",
    "users_val = unique_users[:split_index]\n",
    "users_test = unique_users[split_index:]\n",
    "\n",
    "# create val and test\n",
    "test = test_prepared[test_prepared[data_description['users']].isin(users_test)]\n",
    "val = test_prepared[test_prepared[data_description['users']].isin(users_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform successive evaluation, we need to have access to the user's history in chronological order. Let's create a dictionary with users as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}\n",
    "for user, item, rating, timestamp in test.values:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Association Rules (AR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{score}_{AR}(u, i) = \\text{PairCount}_{AR}(i_{|I_u|}, i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{PairCount}_{AR}(i, j) = |U_i\\cap U_j|\n",
    "$$\n",
    "\n",
    "$I_u$ - interaction history of user $u$, $U_i$ - set of users who interacted with item $i$, $i_{|I_u|}$ - last item of user $u$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import diags\n",
    "\n",
    "class AR:\n",
    "    def __init__(self, model_config=None) -> None:\n",
    "        pass\n",
    "    \n",
    "    def build(self, data, data_description):\n",
    "        '''\n",
    "        Builds association rules matrix.\n",
    "        '''\n",
    "        self.rules = ...\n",
    "        \n",
    "    def recommend(self, data, data_description):\n",
    "        '''\n",
    "        Generate scores for given data.\n",
    "        '''\n",
    "        # Drop duplicates, keeping the last interaction for each user\n",
    "        \n",
    "        scores = ...\n",
    "        return scores\n",
    "\n",
    "    def recommend_sequential(self, target_seq, seen_seq, user):\n",
    "        '''\n",
    "        Generate scores for sequential evaluation - \n",
    "        subsequently add 1 item from target sequence to the seen sequence\n",
    "        and generate predictions for the resulting history.\n",
    "        '''\n",
    "        \n",
    "        scores_seq = ...\n",
    "        return scores_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Rules (MC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{score}_{SR}(u, i) = \\sum_{j \\in I_u  \\backslash \\{i\\}} \\textbf{1}[j=i_{|I_u|}]\\text{PairCount}_{SR}(j \\rightarrow i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{PairCount}_{SR}(j \\rightarrow i) = \\sum_{v\\in U} \\textbf{1}[j\\rightarrow_v i]\n",
    "$$\n",
    "\n",
    "where $j\\rightarrow_u i$ means that item $i$ follows item $j$ in the interaction history of user $u$. $U$ is the set of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR:\n",
    "    def __init__(self, model_config=None) -> None:\n",
    "        pass\n",
    "    \n",
    "    def build(self, data, data_description):\n",
    "        'Builds sequential rules of size two'\n",
    "        \n",
    "        self.rules = ...\n",
    "\n",
    "    def recommend(self, data, data_description):\n",
    "        '''\n",
    "        Generate scores for given data.\n",
    "        '''\n",
    "        scores = ...\n",
    "        return scores\n",
    "    \n",
    "    def recommend_sequential(self, target_seq, seen_seq, user):\n",
    "        '''\n",
    "        Generate scores for sequential evaluation - \n",
    "        subsequently add 1 item from target sequence to the seen sequence\n",
    "        and generate predictions for the resulting history.\n",
    "        '''\n",
    "        scores = ...\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of our Association and Sequential Rule methods we should also build some baselines - random and popular-based. This also serves as sanity check for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random:\n",
    "    def __init__(self, model_config=None) -> None:\n",
    "        # for reproducibility, not a hyperparameter\n",
    "        self.seed = model_config['seed']\n",
    "        self.rng = np.random.default_rng(seed=model_config['seed'])\n",
    "    \n",
    "    def build(self, data, data_description):\n",
    "        self.n_items = data_description['n_items']\n",
    "        \n",
    "    def recommend(self, data, data_description):\n",
    "        n_users = data.nunique()[data_description['users']]\n",
    "        n_items = data_description['n_items']\n",
    "        return self.rng.random((n_users, n_items))\n",
    "    \n",
    "    def recommend_sequential(self, target_seq, seen_seq, user):\n",
    "        return self.rng.random((len(target_seq), self.n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Popular:\n",
    "    def __init__(self, model_config=None) -> None:\n",
    "        pass\n",
    "    \n",
    "    def build(self, data, data_description):\n",
    "        item_popularity = data[data_description['items']].value_counts()\n",
    "        n_items = item_popularity.index.max() + 1\n",
    "        popularity_scores = np.zeros(n_items,)\n",
    "        popularity_scores[item_popularity.index] = item_popularity.values\n",
    "        self.popularity_scores = popularity_scores\n",
    "        \n",
    "    def recommend(self, data, data_description):\n",
    "        n_users = data.nunique()[data_description['users']]\n",
    "        return np.tile(self.popularity_scores, (n_users, 1))\n",
    "    \n",
    "    def recommend_sequential(self, target_seq, seen_seq, user):\n",
    "        return np.tile(self.popularity_scores, (len(target_seq), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downvote_seen_items_sequence(scores, seen_sequence):\n",
    "    assert isinstance(scores, np.ndarray), 'Scores must be a dense numpy array!'\n",
    "    assert scores.shape[0] == len(seen_sequence), 'Scores size is different from sequence length!'\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successive_evaluation(test_dict, model, topn=10):\n",
    "    cum_hits = 0\n",
    "    cum_reciprocal_ranks = 0.\n",
    "    cum_discounts = 0.\n",
    "    unique_recommendations = set()\n",
    "    total_count = 0\n",
    "    \n",
    "    for user in tqdm(test_dict):\n",
    "        seen_seq = ...\n",
    "        test_seq = ...\n",
    "        num_predictions = len(test_seq)\n",
    "        if not num_predictions: # if no test items left - skip user\n",
    "            continue\n",
    "        scores = model.recommend_sequential(test_seq, seen_seq, user)\n",
    "        downvote_seen_items_sequence(scores, test_dict[user][:-1])\n",
    "        predicted_items = topn_recommendations(scores, topn=topn)\n",
    "        \n",
    "        hit_steps, hit_index = np.where(predicted_items == np.atleast_2d(test_seq).T)\n",
    "        unique_recommendations.update(predicted_items.ravel())\n",
    "\n",
    "        num_hits = hit_index.size\n",
    "        if num_hits:\n",
    "            cum_hits += num_hits\n",
    "            cum_reciprocal_ranks += np.sum(1. / (hit_index+1))\n",
    "            cum_discounts += np.sum(1. / np.log2(hit_index+2))\n",
    "\n",
    "        total_count += num_predictions\n",
    "\n",
    "    hr = cum_hits / total_count\n",
    "    mrr = cum_reciprocal_ranks / total_count\n",
    "    dcg = cum_discounts / total_count\n",
    "    cov = len(unique_recommendations) / scores.shape[1]\n",
    "    results = pd.DataFrame(\n",
    "        data = {f'{model.__class__.__name__}': [hr, mrr, dcg, cov]},\n",
    "        index = [f'{metric}@{topn}' for metric in ['HR', 'MRR', 'NDCG', 'COV']]\n",
    "    )\n",
    "    return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description_rules = {\n",
    "    'n_users':training.nunique()['userid'],\n",
    "    'n_items':training.nunique()['movieid'],\n",
    "    'users':'userid',\n",
    "    'items':'movieid',\n",
    "    'feedback':'rating',\n",
    "    'timestamp':'timestamp'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model = AR()\n",
    "ar_model.build(training, data_description_rules)\n",
    "results_ar = successive_evaluation(test_dict, ar_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_model = SR()\n",
    "sr_model.build(training, data_description_rules)\n",
    "results_sr = successive_evaluation(test_dict, sr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_model = Popular()\n",
    "pop_model.build(training, data_description_rules)\n",
    "results_pop = successive_evaluation(test_dict, pop_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_model = Random({'seed':0})\n",
    "rand_model.build(training, data_description_rules)\n",
    "results_rand = successive_evaluation(test_dict, rand_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([results_sr, results_ar, results_pop, results_rand], axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be done to improve model's quality?\n",
    "- Allow counting not consequent pairs of items (e.g. count $\\textbf{A} \\rightarrow \\textbf{B}$ and $\\textbf{A}\\rightarrow \\text{C} \\rightarrow \\text{D} \\rightarrow \\textbf{B}$, probably with weighting proportional to the inverse number of items between the pair)\n",
    "- This also may help in the case of sparse datasets, where there is hard to mine association rules (density of ML-1m is about $4\\%$, which is pretty high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, apart from better accuracy metrics (HR and MRR), the sequential rules model provides much more diverse recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the sparsity of rules matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'AR rules density: {ar_model.rules.size / ar_model.rules.shape[0] ** 2:.2f}')\n",
    "print(f'SR rules density: {sr_model.rules.size / sr_model.rules.shape[0] ** 2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the sparsity pattern of the left 100 $\\times$ 100 corner of rules matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, constrained_layout=True)\n",
    "ax[0].spy(ar_model.rules[:100, :100], markersize=1, label='AR')\n",
    "ax[0].set_title('AR')\n",
    "ax[1].spy(sr_model.rules[:100, :100], markersize=1, label='SR')\n",
    "ax[1].set_title('SR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, constrained_layout=True, figsize=(15, 7))\n",
    "\n",
    "im0 = ax[0].imshow(ar_model.rules[:100, :100].toarray(), cmap='Greys')\n",
    "ax[0].set_title('AR Heatmap')\n",
    "divider0 = make_axes_locatable(ax[0])\n",
    "cax0 = divider0.append_axes(\"right\", size=\"5%\", pad=0.0)\n",
    "fig.colorbar(im0, ax=ax[0], cax=cax0)\n",
    "\n",
    "im1 = ax[1].imshow(sr_model.rules[:100, :100].toarray(), cmap='Greys')\n",
    "ax[1].set_title('SR Heatmap')\n",
    "divider1 = make_axes_locatable(ax[1])\n",
    "cax1 = divider1.append_axes(\"right\", size=\"5%\", pad=0.0)\n",
    "fig.colorbar(im1, ax=ax[1], cax=cax1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(sorted(norm(ar_model.rules, axis=1)), label='AR')\n",
    "plt.semilogy(sorted(norm(sr_model.rules, axis=1)), label='SR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
